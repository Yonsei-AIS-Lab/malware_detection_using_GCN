import torch
import torch.nn as nn
from torch.nn import Linear
from torch_geometric.nn import GCNConv
from torch_geometric.loader import DataLoader
import torch.nn.functional as F

class GCN(torch.nn.Module):
    def __init__(self, nb_features, nb_classes, nb_layers, hidden_size):
        super().__init__()

        self.layers = torch.nn.ModuleList([])
        for i in range(nb_layers):
            if i == 0:
                self.layers.append(GCNConv(nb_features, hidden_size))
            else:
                self.layers.append(GCNConv(hidden_size, hidden_size))
        self.conv_out = GCNConv(hidden_size, nb_classes)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        for i, layer in enumerate(self.layers):
            x = layer(x, edge_index)
            x = F.relu(x)
        
        x = self.conv_out(x, edge_index)

        return F.log_softmax(x, dim=1)
    
def train(model, train, test, epochs):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)


    log = {}
    log['train_loss'] = []
    log['train_acc'] = []
    log['test_loss'] = []
    log['test_acc'] = []

    for epoch in range(epochs):
        train_cnt = 0
        train_loss = 0
        train_acc = 0

        model.train()
        optimizer.zero_grad()

        for data in train:
            data = data.to(device)
            target = data.y.to(device)

            output = model(data)

            pred = torch.argmax(output, dim=1)
            correct = torch.eq(pred, target).sum().item()
            acc = correct / len(target)

            loss = F.nll_loss(output, target)
            loss.backward()
            optimizer.step()

            train_loss += loss
            train_acc += acc
            train_cnt += 1

        train_loss /= train_cnt
        train_acc /= train_cnt

        test_loss, test_acc = validation(device, model, test)

        log['train_loss'].append(train_loss.detach().item())
        log['train_acc'].append(train_acc)
        log['test_loss'].append(test_loss.detach().item())
        log['test_acc'].append(test_acc)

        print(f'{epoch+1:>3} Epochs: t_loss[{train_loss:.2f}], t_acc[{train_acc*100:.2f} %]  /  loss[{test_loss:.2f}], acc[{test_acc*100:.2f} %]')

    return log

def validation(device, model, test_loader):
    test_cnt = 0
    test_loss = 0
    test_acc = 0

    model.eval()
    with torch.no_grad():
        for data in test_loader:
            data = data.to(device)
            target = data.y.to(device)

            output = model(data)

            pred = torch.argmax(output, dim=1)
            correct = torch.eq(pred, target).sum().item()
            acc = correct / len(target)

            loss = F.nll_loss(output, target)

            test_loss += loss
            test_acc += acc
            test_cnt += 1
        test_loss /= test_cnt            
        test_acc /= test_cnt

    return test_loss, test_acc