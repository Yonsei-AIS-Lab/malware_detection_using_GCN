import pandas as pd
import numpy as np
import torch
from torch_geometric.data import Data

def get_data_info(data):
    """
    0: Normal
    1: Extortion Virus
    2: Mining Program
    3: DDoS Trojan Horse
    4: Worm Virus
    5: Infectious Virus
    6: Backdoor Program
    7: Trojan horse Program
    """
    label = data.groupby(['file_id', 'label'])['label'].unique()
    counts = label.value_counts()
    features = data['api'].unique()
    files = data['file_id'].unique()

    nb_features = len(features)
    nb_data = len(data)
    nb_files = len(files)

    print('-----| Get Data Information |-----')
    print(f"- Data     : {nb_data:<6}\n"
        f"- Features : {nb_features:<6}\n"
        f"- Files    : {nb_files:<6}\n")
    
    #print(counts)

    return nb_features, nb_data, nb_files

def print_progress(cur, total):
    print(f"## Progress: {cur+1}/{total} ##", end='\r')

def split_per_id(data, nb_files):
    split_per_flie_id = []
    print('-----| Split Per File ID |-----')
    for i in range(nb_files):
        split_per_flie_id.append(data[data['file_id']==i+1])
        print_progress(i, nb_files)
    print('\n')

    return split_per_flie_id

def creat_api2idx(data):
    api_names = data['api'].unique()

    api2idx = {}
    api2idx['[UNK]'] = 0
    for i, api_name in enumerate(api_names):
        api2idx[api_name] = i+1

    return api2idx

def encode_api_name(data_split_per_id, api2idx):
    file_len = len(data_split_per_id)
    files = []
    labels = []
    print('-----| Encode API Name |-----')

    for i, datas in enumerate(data_split_per_id):
        encoded_data = datas.copy()
        encoded_apis = (encoded_data['api'].map(api2idx)).fillna(0).astype(int).to_list()
        label = encoded_data['label'].to_list()

        files.append(encoded_apis)
        labels.append(label)

        if len(encoded_apis) != len(label):
            print("[!!!ERORR!!!] nb_Data != nb_Label")
            print(f'{len(datas)}, {len(label)}')
        print_progress(i, file_len)
    print('\n')
    
    return files, labels

def create_feature_matrix(files, api2idx):
    file_len = len(files)
    
    nb_features = len(api2idx)
    print('-----| Create Feature Matrix |-----')

    results = []
    for i, nodes in enumerate(files):
        feature = np.zeros(nb_features)
        for node in nodes:
            feature[node] += 1
        results.append(feature)
        print_progress(i, file_len)
    
    print('\n')

    return np.array(results)

def create_edge_index(files):
    print('-----| Create Adjacency Matrix |-----')
    file_len = len(files)

    results = []
    for i, nodes in enumerate(files):
        nb_edge = len(nodes)-1
        src, dst = nodes[:nb_edge], nodes[1:]

        edge_idx = np.array([src, dst])

        results.append(edge_idx)
        print_progress(i, file_len)
    print('\n')

    return results

def create_geometric(feature_mat, edge_idx, labels):
    print('-----| Create Geometric Data |-----')

    nb_data = len(labels)

    results = []
    for i in range(nb_data):
        x = torch.tensor(feature_mat[i].reshape(-1, 1))
        edge_index = torch.tensor(edge_idx[i])
        y = torch.tensor(labels[i])

        results.append(Data(x=x, edge_index=edge_index, y=y))
        print_progress(i, nb_data)
    print('\n')

    return results

def preprocessing_graph_data(data):
    nb_features, nb_data, nb_files = get_data_info(data)

    data_split_per_id = split_per_id(data, nb_files)

    api2idx = creat_api2idx(data)

    files, labels = encode_api_name(data_split_per_id, api2idx)

    feature_mat = create_feature_matrix(files, api2idx)
    edge_idx = create_edge_index(files)

    processed = create_geometric(feature_mat, edge_idx, labels)

    return processed