{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_add_pool\n",
    "from torch_geometric.datasets import MalNetTiny\n",
    "from torch_geometric.transforms import LocalDegreeProfile\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers, hidden_dim, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.args = {\"num_layers\":num_layers,\n",
    "                    \"hidden_dim\":hidden_dim,\n",
    "                    \"dropout\":dropout}\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList([])\n",
    "        for i in range(self.args[\"num_layers\"]):\n",
    "            if i == 0:\n",
    "                self.layers.append(GCNConv(5, self.args[\"hidden_dim\"]))\n",
    "            else:\n",
    "                self.layers.append(GCNConv(self.args[\"hidden_dim\"], self.args[\"hidden_dim\"]))\n",
    "        \n",
    "        self.fc1 = Linear(self.args[\"hidden_dim\"], self.args[\"hidden_dim\"])\n",
    "        self.fc2 = Linear(self.args[\"hidden_dim\"], 5)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.args[\"dropout\"] > 0:\n",
    "            x = F.dropout(x, p=self.args[\"dropout\"], training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNConv(5, 128)\n",
      "    (1-5): 5 x GCNConv(128, 128)\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCN(6, 128, 0.0)\n",
    "model.load_state_dict(torch.load('./saves/GCN_932_6_128_0_0.001_200.pt', map_location=torch.device('cpu')))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "transform_data = LocalDegreeProfile()\n",
    "dataset = MalNetTiny(root='./data', transform=transform_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model, data):\n",
    "    # output\n",
    "    output = model(data.x, data.edge_index, data.batch)\n",
    "    \n",
    "    # max confidence\n",
    "    confidence = torch.max(output)\n",
    "    confidence = torch.exp(confidence)\n",
    "\n",
    "    # predicted y\n",
    "    y_hat = torch.argmax(output)\n",
    "\n",
    "    return output, confidence, y_hat\n",
    "\n",
    "def sub_edge(data):\n",
    "    if data.x is None or len(data.x) == 0:\n",
    "        raise ValueError(\"data.x is empty or not defined.\")\n",
    "    \n",
    "    # select random edge\n",
    "    edge_list = data.edge_index.T.tolist()\n",
    "    sel_edge = edge_list[np.random.choice(len(edge_list))]\n",
    "    sel_edge = torch.tensor(sel_edge, dtype=torch.long).view(2, 1)\n",
    "\n",
    "    # sub edge\n",
    "    mask = (data.edge_index != sel_edge).all(0)\n",
    "    subbed_edge_idx = data.edge_index[:, mask]\n",
    "\n",
    "    # Recalculate LDP\n",
    "    subbed_data = transform_data(data.__class__().from_dict({\n",
    "        'edge_index': subbed_edge_idx\n",
    "    }))\n",
    "\n",
    "    return subbed_data, sel_edge\n",
    "\n",
    "def attack_model(model, data, iter_max = 100):\n",
    "    # prediction for compare\n",
    "    init_output, init_conf, init_y_hat = get_pred(model, data)    \n",
    "\n",
    "    log_conf = []\n",
    "    nb_iter = 0\n",
    "\n",
    "    prev_data = data\n",
    "    prev_conf = init_conf\n",
    "\n",
    "    for i in range(iter_max):\n",
    "        # sub edge\n",
    "        subbed_data, subbed_edge = sub_edge(prev_data)\n",
    "        nb_iter += 1\n",
    "\n",
    "        # no edge sub\n",
    "        if subbed_edge is None:\n",
    "            return -1, log_conf, init_output, None\n",
    "        \n",
    "        # predict using subbed data\n",
    "        output, conf, y_hat = get_pred(model, subbed_data)\n",
    "        log_conf.append(conf)\n",
    "\n",
    "        # 레이블이 바뀌면!\n",
    "        if y_hat != init_y_hat:\n",
    "            return nb_iter, conf, init_y_hat, y_hat\n",
    "        \n",
    "        # confidence가 줄어들면!\n",
    "        elif conf < prev_conf:\n",
    "            prev_data = subbed_data\n",
    "            prev_conf = conf\n",
    "            nb_iter += 1\n",
    "\n",
    "        # 줄어들지 않으면 다시 반복\n",
    "        else:\n",
    "            nb_iter -= 1\n",
    "    \n",
    "    # iteration 다돌면 실패 반환\n",
    "    return -1, log_conf, init_output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch_geometric\\data\\storage.py:304: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 100번째 데이터 : 27번째 iteration에서 공격 성공\n",
      "2 / 100번째 데이터 : 45번째 iteration에서 공격 성공\n",
      "3 / 100번째 데이터 : 17번째 iteration에서 공격 성공\n",
      "4 / 100번째 데이터 : 3번째 iteration에서 공격 성공\n",
      "5 / 100번째 데이터 : 3번째 iteration에서 공격 성공\n",
      "6 / 100번째 데이터 : 9번째 iteration에서 공격 성공\n",
      "7 / 100번째 데이터 : 39번째 iteration에서 공격 성공\n",
      "8 / 100번째 데이터 : 21번째 iteration에서 공격 성공\n",
      "9 / 100번째 데이터 : 1번째 iteration에서 공격 성공\n",
      "10 / 100번째 데이터 : 33번째 iteration에서 공격 성공\n",
      "11 / 100번째 데이터 : 21번째 iteration에서 공격 성공\n",
      "12 / 100번째 데이터 : 45번째 iteration에서 공격 성공\n",
      "13 / 100번째 데이터 : 7번째 iteration에서 공격 성공\n",
      "14 / 100번째 데이터 : 9번째 iteration에서 공격 성공\n",
      "15 / 100번째 데이터 : 1번째 iteration에서 공격 성공\n",
      "16 / 100번째 데이터 : 1번째 iteration에서 공격 성공\n",
      "17 / 100번째 데이터 : 37번째 iteration에서 공격 성공\n",
      "18 / 100번째 데이터 : 47번째 iteration에서 공격 성공\n",
      "19 / 100번째 데이터 : 55번째 iteration에서 공격 성공\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m fail \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_attack):\n\u001b[1;32m----> 6\u001b[0m     nb_iter, log_conf, init_pred, after_pred \u001b[38;5;241m=\u001b[39m \u001b[43mattack_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nb_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_attack\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m번째 데이터 : 공격 실패\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[69], line 54\u001b[0m, in \u001b[0;36mattack_model\u001b[1;34m(model, data, iter_max)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, log_conf, init_output, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# predict using subbed data\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m output, conf, y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mget_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubbed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m log_conf\u001b[38;5;241m.\u001b[39mappend(conf)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 레이블이 바뀌면!\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m, in \u001b[0;36mget_pred\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pred\u001b[39m(model, data):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# output\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# max confidence\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output)\n",
      "File \u001b[1;32mc:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[66], line 20\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m---> 20\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m global_add_pool(x, batch)\n",
      "File \u001b[1;32mc:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:229\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m    232\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight,\n\u001b[0;32m    233\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\JSK\\anaconda3\\envs\\cpu_torch\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_attack = 100\n",
    "\n",
    "success = []\n",
    "fail = []\n",
    "for idx in range(nb_attack):\n",
    "    nb_iter, log_conf, init_pred, after_pred = attack_model(model, dataset[idx])\n",
    "    if nb_iter == -1:\n",
    "        print(f\"{idx+1} / {nb_attack}번째 데이터 : 공격 실패\")\n",
    "        fail.append(idx)\n",
    "    else:\n",
    "        print(f\"{idx+1} / {nb_attack}번째 데이터 : {nb_iter}번째 iteration에서 공격 성공\")\n",
    "        success.append(nb_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공격 성공률: 90.00\n",
      "평균 추가 엣지 수: 16.11\n"
     ]
    }
   ],
   "source": [
    "print(f'공격 성공률: {len(success) / nb_attack * 100:.2f}')\n",
    "print(f'평균 추가 엣지 수: {np.mean(success):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malware_GCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
